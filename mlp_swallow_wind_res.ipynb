{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef82987f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import metpy\n",
    "from metpy import calc\n",
    "from metpy.units import units\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "from keras.layers import Add\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import keras.losses as losses\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import warnings  # Supress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # set this to the ID of the GPU you want to use\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3bb5f3b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "#     df = pd.read_csv('../qiancengfeng/dataset/qiancengfeng_leibao.csv')\n",
    "    df = pd.read_csv('../../qiancengfeng/dataset/qiancengfeng_leibao_diag.csv')\n",
    "    df_1 = pd.read_csv('../../qiancengfeng/dataset/qiancengfeng_leibao_2022.csv')\n",
    "    df.time = pd.to_datetime(df['time'])\n",
    "    df.stime = pd.to_datetime(df['stime'], format='ISO8601')\n",
    "    df=df.sort_values(['stime','dtime']).reset_index(drop=True) \n",
    "    \n",
    "    df_1.time = pd.to_datetime(df_1['time'])\n",
    "    df_1.stime = pd.to_datetime(df_1['stime'], format='ISO8601')\n",
    "    df_1=df_1.sort_values(['stime','dtime']).reset_index(drop=True) \n",
    "   \n",
    "    df_1['time_order'] = df_1.stime.dt.hour\n",
    "    \n",
    "    feats_name = ['level', 'time', 'stime', 'dtime','time_order', \n",
    "            'id', 'lon', 'lat','sw_max1','sw_max2', 'v100', 'tcc', 'sf',\n",
    "           'msl', 'lsp', 'cape', 'sst', 'lcc', 'sd', 'cp', 'u100', 'skt',\n",
    "           'tpe', 'sp', 'd2m', 'u10', 'v10', 't2m', 'p3020', 'fg310', 'tcwv',\n",
    "           'rsn', 'deg0l', 'mn2t3', 'mx2t3', 'tcw', 'fal', 'fzra', 'capes',\n",
    "           '1000t', '950t', '925t', '900t', '850t', '800t', '700t',\n",
    "           '600t', '500t', '400t', '300t', '250t', '200t', '150t', '100t',\n",
    "           '70t', '50t', '20t', '10t', '1000gh', '950gh', '925gh', '900gh',\n",
    "           '850gh', '800gh', '700gh', '600gh', '500gh', '400gh', '300gh',\n",
    "           '250gh', '200gh', '150gh', '100gh', '70gh', '50gh', '20gh', '10gh',\n",
    "           '1000u', '950u', '925u', '900u', '850u', '800u', '700u', '600u',\n",
    "           '500u', '400u', '300u', '250u', '200u', '150u', '100u', '70u',\n",
    "           '50u', '20u', '10u', '1000v', '950v', '925v', '900v', '850v',\n",
    "           '800v', '700v', '600v', '500v', '400v', '300v', '250v', '200v',\n",
    "           '150v', '100v', '70v', '50v', '20v', '10v', '1000r', '950r',\n",
    "           '925r', '900r', '850r', '800r', '700r', '600r', '500r', '400r',\n",
    "           '300r', '250r', '200r', '150r', '100r', '70r', '50r', '20r', '10r',\n",
    "           '1000w', '950w', '925w', '900w', '850w', '800w', '700w', '600w',\n",
    "           '500w', '400w', '300w', '250w', '200w', '150w', '100w', '70w',\n",
    "           '50w', '20w', '10w', '1000q', '950q', '925q', '900q', '850q',\n",
    "           '800q', '700q', '600q', '500q', '400q', '300q', '250q', '200q',\n",
    "           '150q', '100q', '70q', '50q', '20q', '10q', '1000d', '950d',\n",
    "           '925d', '900d', '850d', '800d', '700d', '600d', '500d', '400d',\n",
    "           '300d', '250d', '200d', '150d', '100d', '70d', '50d', '20d', '10d',\n",
    "           '1000pv', '950pv', '925pv', '900pv', '850pv', '800pv', '700pv',\n",
    "           '600pv', '500pv', '400pv', '300pv', '250pv', '200pv', '150pv',\n",
    "           '100pv', '70pv', '50pv', '20pv', '10pv']\n",
    "\n",
    "    \n",
    "\n",
    "    df = df[feats_name]\n",
    "    df_1 = df_1[feats_name]\n",
    "    df = pd.concat([df,df_1],axis=0)\n",
    "    \n",
    "\n",
    "    # 有可能有两个dtime=0,获得最一开始的\n",
    "    df['previous_time'] = df['time'].shift(1)\n",
    "    # 筛选符合条件的行\n",
    "    condition = (df['time'] == df['previous_time']) & (df['dtime'] == 0)\n",
    "    df = df[~condition]\n",
    "    # 删除辅助列\n",
    "    df = df.drop('previous_time', axis=1)\n",
    "    return df,feats_name\n",
    "\n",
    "# 处理异常值 *\n",
    "def process_outlier(df,feats):\n",
    "    _ = df[feats[7:]]\n",
    "    # 1. 计算每个气象要素的平均值和标准差\n",
    "    mean_values = _.mean()\n",
    "    std_values = _.std()\n",
    "    # 2. 根据三倍标准差法，设定异常值的阈值\n",
    "    threshold = 3 * std_values\n",
    "    # 3. 遍历每个气象要素的数值，将超过设定阈值的值标记为异常值\n",
    "    is_outlier = (_ > mean_values + threshold) | (_ < mean_values - threshold)\n",
    "    # 4. 对于标记为异常值的数据，可以根据需要选择删除、替换或进行插补处理\n",
    "    # 假设你选择删除异常值\n",
    "    df = df[~is_outlier.any(axis=1)]\n",
    "    df = df.query('sw_max1<20 and sw_max2<20')\n",
    "     \n",
    "    return df\n",
    "\n",
    "def speed_direction_features(df_):\n",
    "    # 构建风向风速\n",
    "    df_['wind_speed10'] = metpy.calc.wind_speed(df_['u10'].values * units('m/s'), df_['v10'].values * units('m/s'))\n",
    "    df_['wind_direction10'] = metpy.calc.wind_direction(df_['u10'].values * units('m/s'),\n",
    "                                                        df_['v10'].values * units('m/s'))\n",
    "\n",
    "    df_['wind_speed100'] = metpy.calc.wind_speed(df_['u100'].values * units('m/s'),\n",
    "                                                 df_['v100'].values * units('m/s'))\n",
    "    df_['wind_direction100'] = metpy.calc.wind_direction(df_['u100'].values * units('m/s'),\n",
    "                                                         df_['v100'].values * units('m/s'))\n",
    "    \n",
    "    df_['wind_speed_L1000'] = metpy.calc.wind_speed(df_['1000u'].values * units('m/s'),\n",
    "                                                 df_['1000v'].values * units('m/s'))\n",
    "    df_['wind_direction_L1000'] = metpy.calc.wind_direction(df_['1000u'].values * units('m/s'),\n",
    "                                                         df_['1000v'].values * units('m/s'))\n",
    "    \n",
    "    df_['wind_speed_L950'] = metpy.calc.wind_speed(df_['950u'].values * units('m/s'),\n",
    "                                                 df_['950v'].values * units('m/s'))\n",
    "    df_['wind_direction_L950'] = metpy.calc.wind_direction(df_['950u'].values * units('m/s'),\n",
    "                                                         df_['950v'].values * units('m/s'))\n",
    "    \n",
    "    df_['wind_speed_L925'] = metpy.calc.wind_speed(df_['925u'].values * units('m/s'),\n",
    "                                                 df_['925v'].values * units('m/s'))\n",
    "    df_['wind_direction_L925'] = metpy.calc.wind_direction(df_['925u'].values * units('m/s'),\n",
    "                                                         df_['925v'].values * units('m/s'))\n",
    "    \n",
    "    df_['wind_speed_L900'] = metpy.calc.wind_speed(df_['900u'].values * units('m/s'),\n",
    "                                                 df_['900v'].values * units('m/s'))\n",
    "    df_['wind_direction_L900'] = metpy.calc.wind_direction(df_['900u'].values * units('m/s'),\n",
    "                                                         df_['900v'].values * units('m/s'))\n",
    "    \n",
    "    \n",
    "    df_['wind_direction_L500'] = metpy.calc.wind_direction(df_['500u'].values * units('m/s'),\n",
    "                                                         df_['500v'].values * units('m/s'))\n",
    "    \n",
    "    df_['wind_direction_L700'] = metpy.calc.wind_direction(df_['700u'].values * units('m/s'),\n",
    "                                                         df_['700v'].values * units('m/s'))\n",
    "    return df_\n",
    "\n",
    "\n",
    "def get_other_height_speed(df):\n",
    "    df['wind_speed30'] = df['wind_speed10']*(30/10)**(1/7)\n",
    "    df['wind_speed50'] = df['wind_speed10']*(50/10)**(1/7)\n",
    "    df['wind_speed70'] = df['wind_speed10']*(70/10)**(1/7)\n",
    "    return df\n",
    "\n",
    "def get_height_speed_diff(df):\n",
    "    df['wind_speed30_diff'] = df['wind_speed30']-df['wind_speed10']\n",
    "    df['wind_speed50_diff'] = df['wind_speed50']-df['wind_speed30']\n",
    "    df['wind_speed70_diff'] = df['wind_speed70']-df['wind_speed50']\n",
    "    df['wind_speed100_diff'] = df['wind_speed100']-df['wind_speed70']\n",
    "    \n",
    "    df['wind_speed_L925_diff'] = df['wind_speed_L925']-df['wind_speed_L900']\n",
    "    df['wind_speed_L950_diff'] = df['wind_speed_L950']-df['wind_speed_L925']\n",
    "    df['wind_speed_L1000_diff'] = df['wind_speed_L1000']-df['wind_speed_L950']\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# 构造时滞特征 *\n",
    "def get_lag_features(df,ori_feats):\n",
    "    df=df.sort_values(['stime','dtime']).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    for feat in ori_feats:\n",
    "        df[feat+'_s1'] = df.groupby('stime')[feat].shift(1)\n",
    "        \n",
    "    # 构造后可能首尾出现空值\n",
    "    df = df.fillna(method='bfill')\n",
    "    df = df.fillna(method='ffill')\n",
    "\n",
    "    return df\n",
    "\n",
    "# 构造窗口统计特征 *\n",
    "def get_window(df,ori_feats):\n",
    "    df=df.sort_values(['stime','dtime']).reset_index(drop=True) \n",
    "    \n",
    "    for feat in ori_feats:\n",
    "        # window=8的原因是8为一个周期\n",
    "        df[feat+\"_max_8\"] = df.groupby('stime')[feat].rolling(window=8).max().reset_index(drop=True)\n",
    "        df[feat+\"_avg_8\"] = df.groupby('stime')[feat].rolling(window=8).mean().reset_index(drop=True)\n",
    "        df[feat+\"_var_8\"] = df.groupby('stime')[feat].rolling(window=8).var().reset_index(drop=True)\n",
    "        \n",
    "\n",
    "\n",
    "    df = df.fillna(method='bfill')\n",
    "    df = df.fillna(method='ffill')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 时间特征 *   \n",
    "def get_time_features(df):\n",
    "#     df['year'] = df.time.dt.year\n",
    "    df['month'] = df.time.dt.month\n",
    "    df['day'] = df.time.dt.day\n",
    "    df['hour'] = df.time.dt.hour\n",
    "    return df\n",
    "\n",
    "# 特征筛选 *\n",
    "def select_features(df,thus):\n",
    "    \n",
    "    df_corr = df.drop_duplicates(subset=['time'])\n",
    "    df_corr_1_res = pd.DataFrame(df_corr.corr()['sw_max1'])\n",
    "    df_corr_1_res.sort_values('sw_max1',ascending=False)\n",
    "    df_corr_1_res.to_csv('../../qiancengfeng/corr/sw_max1_corr.csv')\n",
    "    \n",
    "\n",
    "    df_corr_2_res = pd.DataFrame(df_corr.corr()['sw_max2'])\n",
    "    df_corr_2_res.sort_values('sw_max2',ascending=False)\n",
    "    df_corr_2_res.to_csv('../../qiancengfeng/corr/sw_max2_corr.csv')\n",
    "\n",
    "    # df_corr_1_res = df_corr_1_res.query('abs(sw_max1)>=0.2')\n",
    "    # df_corr_2_res = df_corr_2_res.query('abs(sw_max2)>=0.2')\n",
    "    df_corr_1_res = df_corr_1_res.query('abs(sw_max1)>=@thus')\n",
    "    df_corr_2_res = df_corr_2_res.query('abs(sw_max2)>=@thus')\n",
    "    feats = list(set(df_corr_1_res.index).union(set(df_corr_2_res.index)))\n",
    "    feats = list(filter(lambda x: x not in ['sw_max1','sw_max2','time','stime','time_order'] , feats))\n",
    "    print(f'corr>{thus}:{feats}')\n",
    "    \n",
    "   \n",
    "    feats_name = ['level', 'time', 'dtime','stime', 'id', 'lon', 'lat','type','time_order','sw_max1','sw_max2']+feats\n",
    "    return feats_name\n",
    "\n",
    "def query_cut_dataset(df,ageing,feats_name):\n",
    "    df = df.set_index('stime')\n",
    "    df.loc[:'2021-12-31','type'] = 'train'\n",
    "    df.loc['2022-01-01':'2022-12-31','type'] = 'test'\n",
    "#     df = df[:'2022']\n",
    "    df = df.reset_index(drop=False)\n",
    "    \n",
    "    diff = 24\n",
    "    if ageing==24:\n",
    "        diff=25\n",
    "   \n",
    "    \n",
    "#     df_query = df.query(f'dtime>{ageing-diff} and dtime<={ageing}').reset_index(drop=True)\n",
    "    df_query = df.query(f'dtime>=0 and dtime<=120').reset_index(drop=True)\n",
    "    \n",
    "    df_query = df_query[feats_name]\n",
    "\n",
    "    \n",
    "    # 划分测试集-》训练集打乱后划分:去除空值然后shuffle\n",
    "    TRAIN_VAL_DATA = df_query.query(\"type=='train'\").dropna().loc[:,'sw_max1':].sample(frac=1,random_state=0)\n",
    "    TRAIN_DATA = TRAIN_VAL_DATA.iloc[:int(len(TRAIN_VAL_DATA)*0.9)]\n",
    "    VAL_DATA = TRAIN_VAL_DATA.iloc[int(len(TRAIN_VAL_DATA)*0.9):]\n",
    "    TEST_DATA = df_query.query(\"type=='test'\").loc[:,'sw_max1':]\n",
    "    # 测试集填充\n",
    "    TEST_DATA = TEST_DATA.fillna(TEST_DATA.interpolate(limit_area='inside',limit_direction='both'))\n",
    "    TEST_DATA = TEST_DATA.fillna(method='bfill')\n",
    "    TEST_DATA = TEST_DATA.fillna(method='ffill')\n",
    "    \n",
    "    return df,df_query,TRAIN_DATA,VAL_DATA,TEST_DATA\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def load_data(TRAIN_DATA,VAL_DATA,TEST_DATA):\n",
    "    train = TRAIN_DATA\n",
    "    val = VAL_DATA\n",
    "    test = TEST_DATA\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    train = scaler.fit_transform(train)\n",
    "    val = scaler.transform(val)\n",
    "    test = scaler.transform(test)\n",
    "    data = dict()\n",
    "\n",
    "    data[\"train_y\"] = train[:, :2]\n",
    "    data[\"train_X\"] = train[:, 2:]\n",
    "    data[\"val_y\"] = val[:, :2]\n",
    "    data[\"val_X\"] = val[:, 2:]\n",
    "    data[\"test_y\"] = test[:, :2]\n",
    "    data[\"test_X\"] = test[:, 2:]\n",
    "    data[\"scaler\"] = scaler\n",
    "    print(scaler.mean_)\n",
    "    return data\n",
    "\n",
    "def quantile_loss(y_true, y_pred, q):\n",
    "        \n",
    "    error = y_true - y_pred\n",
    "    return tf.reduce_mean(tf.maximum(q * error, (q - 1) * error))\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Add, Input, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_network(input_features=None, num_blocks=3):\n",
    "    inputs = Input(shape=(input_features,), name=\"input\")\n",
    "    x = Dense(512, activation='relu', name=\"hidden_1\")(inputs)\n",
    "    \n",
    "    for i in range(num_blocks):\n",
    "        residual = x\n",
    "        x = Dense(1024, activation='relu', name=f\"hidden_{i+2}_1\")(x)\n",
    "        x = Dense(512, activation='linear', name=f\"hidden_{i+2}_2\")(x)\n",
    "        x = Dropout(0.3, name=f\"dropout_{i+2}\")(x)  # 添加Dropout层\n",
    "        x = Add()([x, residual])\n",
    "        \n",
    "    prediction = Dense(2, activation='linear', name=\"final\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=prediction)\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "     # 定义百分位值\n",
    "#     q = 0.7\n",
    "    q = 0.7  # 设置为0.9，即求解90%百分位损失\n",
    "\n",
    "    # 编译模型时使用百分位损失\n",
    "    model.compile(optimizer=opt, loss=lambda y_true, y_pred: quantile_loss(y_true, y_pred, q))\n",
    "#     model.compile(optimizer=opt, loss=\"mae\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch % 10 == 0 and epoch > 0:\n",
    "        lr = lr * 0.1\n",
    "    return lr\n",
    "\n",
    "def train_model():\n",
    "\n",
    "    input_features = data[\"train_X\"].shape[1]\n",
    "    model = build_network(input_features=input_features)\n",
    "    print(\"Network Structure\")\n",
    "    print(model.summary())\n",
    "    print(\"Training Data Shape: \" + str(data[\"train_X\"].shape))\n",
    "\n",
    "\n",
    "\n",
    "    lr_callback = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "    es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    history  =  model.fit(x=data[\"train_X\"], y=data[\"train_y\"], batch_size=32, epochs=2000,verbose=1,callbacks=[es_callback,lr_callback],\n",
    "              validation_data=(data[\"val_X\"], data[\"val_y\"]))\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()\n",
    "    return model\n",
    "\n",
    "from pykalman import KalmanFilter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def kalman_sm_max(target):\n",
    "    \n",
    "    kalman_res = pd.DataFrame()\n",
    "\n",
    "    # 对每个起始时间应用卡尔曼滤波器\n",
    "    for stime, group in df_res.groupby('stime'):\n",
    "        # 按照dtime排序，保证预报按照时间顺序\n",
    "        group = group.sort_values('dtime')\n",
    "\n",
    "        predicted_sw_max = group['nn_'+target].values  # 获取当前时间序列的神经网络预测的温度值\n",
    "\n",
    "        initial_state = predicted_sw_max[0]  # 初始状态设为神经网络预测的第一个温度值\n",
    "        filtered_state_means = np.zeros(predicted_sw_max.shape)  # 初始化一个用于存放滤波状态均值的数组\n",
    "        filtered_state_covariances = np.zeros(predicted_sw_max.shape)  # 初始化一个用于存放滤波状态协方差的数组\n",
    "        global_error_variance = np.var(predicted_sw_max - filtered_state_means)  # 计算一个全局误差方差\n",
    "\n",
    "        kf = KalmanFilter(transition_matrices=[1],\n",
    "                          observation_matrices=[1],\n",
    "                          initial_state_mean=initial_state,\n",
    "                          initial_state_covariance=1,\n",
    "                          transition_covariance=np.var(predicted_sw_max))\n",
    "\n",
    "        for t in range(len(predicted_sw_max)):\n",
    "            if t == 0:\n",
    "                # 第一个点，用神经网络初始预测值\n",
    "                filtered_state_means[t] = initial_state\n",
    "                filtered_state_covariances[t] = 1\n",
    "            else:\n",
    "                # 更新卡尔曼滤波\n",
    "                filtered_state_means[t], filtered_state_covariances[t] = kf.filter_update(\n",
    "                    filtered_state_mean=filtered_state_means[t-1],\n",
    "                    filtered_state_covariance=filtered_state_covariances[t-1],\n",
    "                    observation=predicted_sw_max[t],\n",
    "                    observation_matrix=np.atleast_2d(1),\n",
    "                    observation_covariance=0.5*global_error_variance\n",
    "                )\n",
    "\n",
    "        # 将处理后的预报添加到新的DataFrame\n",
    "        group['kalman_'+target] = filtered_state_means\n",
    "        kalman_res = pd.concat([kalman_res, group])\n",
    "    return kalman_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a3bbb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df,feats_name = get_data()  # 获得数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46fd1254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_outlier(df,feats_name)  # 处理异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9290d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>time</th>\n",
       "      <th>stime</th>\n",
       "      <th>dtime</th>\n",
       "      <th>time_order</th>\n",
       "      <th>id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>sw_max1</th>\n",
       "      <th>sw_max2</th>\n",
       "      <th>...</th>\n",
       "      <th>400pv</th>\n",
       "      <th>300pv</th>\n",
       "      <th>250pv</th>\n",
       "      <th>200pv</th>\n",
       "      <th>150pv</th>\n",
       "      <th>100pv</th>\n",
       "      <th>70pv</th>\n",
       "      <th>50pv</th>\n",
       "      <th>20pv</th>\n",
       "      <th>10pv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>78457.0</td>\n",
       "      <td>78457</td>\n",
       "      <td>78457</td>\n",
       "      <td>78457.000000</td>\n",
       "      <td>78457.000000</td>\n",
       "      <td>78457.0</td>\n",
       "      <td>7.845700e+04</td>\n",
       "      <td>7.845700e+04</td>\n",
       "      <td>78457.000000</td>\n",
       "      <td>78457.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.845000e+04</td>\n",
       "      <td>7.845000e+04</td>\n",
       "      <td>7.845000e+04</td>\n",
       "      <td>7.845000e+04</td>\n",
       "      <td>7.845000e+04</td>\n",
       "      <td>78450.000000</td>\n",
       "      <td>78450.000000</td>\n",
       "      <td>78450.000000</td>\n",
       "      <td>78450.000000</td>\n",
       "      <td>78450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-14 12:07:01.774985216</td>\n",
       "      <td>2020-01-12 02:56:41.639114752</td>\n",
       "      <td>57.172260</td>\n",
       "      <td>5.365181</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.020300e+02</td>\n",
       "      <td>2.823000e+01</td>\n",
       "      <td>2.909475</td>\n",
       "      <td>3.283945</td>\n",
       "      <td>...</td>\n",
       "      <td>4.777314e-07</td>\n",
       "      <td>5.146018e-07</td>\n",
       "      <td>6.076840e-07</td>\n",
       "      <td>7.473594e-07</td>\n",
       "      <td>1.018405e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-01-01 15:00:00</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.020300e+02</td>\n",
       "      <td>2.823000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.805687e-06</td>\n",
       "      <td>-5.110219e-06</td>\n",
       "      <td>-9.173519e-06</td>\n",
       "      <td>-8.132207e-06</td>\n",
       "      <td>-3.017080e-06</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-08-13 18:00:00</td>\n",
       "      <td>2018-08-10 12:00:00</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.020300e+02</td>\n",
       "      <td>2.823000e+01</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.846909e-07</td>\n",
       "      <td>1.163694e-07</td>\n",
       "      <td>8.694451e-08</td>\n",
       "      <td>1.027461e-07</td>\n",
       "      <td>3.118676e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-02-17 12:00:00</td>\n",
       "      <td>2020-02-16 00:00:00</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.020300e+02</td>\n",
       "      <td>2.823000e+01</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.234976e-07</td>\n",
       "      <td>3.454252e-07</td>\n",
       "      <td>3.226519e-07</td>\n",
       "      <td>3.774367e-07</td>\n",
       "      <td>7.283884e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-05-26 00:00:00</td>\n",
       "      <td>2021-05-23 12:00:00</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.020300e+02</td>\n",
       "      <td>2.823000e+01</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.072759e-07</td>\n",
       "      <td>7.261644e-07</td>\n",
       "      <td>7.965073e-07</td>\n",
       "      <td>9.650466e-07</td>\n",
       "      <td>1.418186e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>2022-12-31 00:00:00</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.020300e+02</td>\n",
       "      <td>2.823000e+01</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.684358e-06</td>\n",
       "      <td>1.005564e-05</td>\n",
       "      <td>1.597344e-05</td>\n",
       "      <td>1.914169e-05</td>\n",
       "      <td>5.403170e-06</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.866818</td>\n",
       "      <td>5.966361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.421095e-14</td>\n",
       "      <td>1.065821e-14</td>\n",
       "      <td>1.775539</td>\n",
       "      <td>1.786028</td>\n",
       "      <td>...</td>\n",
       "      <td>5.502051e-07</td>\n",
       "      <td>7.263126e-07</td>\n",
       "      <td>9.464603e-07</td>\n",
       "      <td>1.143633e-06</td>\n",
       "      <td>1.097956e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         level                           time                          stime   \n",
       "count  78457.0                          78457                          78457  \\\n",
       "mean       0.0  2020-01-14 12:07:01.774985216  2020-01-12 02:56:41.639114752   \n",
       "min        0.0            2017-01-01 15:00:00            2017-01-01 00:00:00   \n",
       "25%        0.0            2018-08-13 18:00:00            2018-08-10 12:00:00   \n",
       "50%        0.0            2020-02-17 12:00:00            2020-02-16 00:00:00   \n",
       "75%        0.0            2021-05-26 00:00:00            2021-05-23 12:00:00   \n",
       "max        0.0            2022-12-31 21:00:00            2022-12-31 00:00:00   \n",
       "std        0.0                            NaN                            NaN   \n",
       "\n",
       "              dtime    time_order       id           lon           lat   \n",
       "count  78457.000000  78457.000000  78457.0  7.845700e+04  7.845700e+04  \\\n",
       "mean      57.172260      5.365181      2.0  1.020300e+02  2.823000e+01   \n",
       "min        0.000000      0.000000      2.0  1.020300e+02  2.823000e+01   \n",
       "25%       24.000000      0.000000      2.0  1.020300e+02  2.823000e+01   \n",
       "50%       51.000000      0.000000      2.0  1.020300e+02  2.823000e+01   \n",
       "75%       84.000000     12.000000      2.0  1.020300e+02  2.823000e+01   \n",
       "max      144.000000     12.000000      2.0  1.020300e+02  2.823000e+01   \n",
       "std       39.866818      5.966361      0.0  1.421095e-14  1.065821e-14   \n",
       "\n",
       "            sw_max1       sw_max2  ...         400pv         300pv   \n",
       "count  78457.000000  78457.000000  ...  7.845000e+04  7.845000e+04  \\\n",
       "mean       2.909475      3.283945  ...  4.777314e-07  5.146018e-07   \n",
       "min        0.000000      0.000000  ... -6.805687e-06 -5.110219e-06   \n",
       "25%        1.500000      2.000000  ...  1.846909e-07  1.163694e-07   \n",
       "50%        2.600000      3.000000  ...  4.234976e-07  3.454252e-07   \n",
       "75%        4.000000      4.000000  ...  7.072759e-07  7.261644e-07   \n",
       "max       15.300000     19.900000  ...  9.684358e-06  1.005564e-05   \n",
       "std        1.775539      1.786028  ...  5.502051e-07  7.263126e-07   \n",
       "\n",
       "              250pv         200pv         150pv         100pv          70pv   \n",
       "count  7.845000e+04  7.845000e+04  7.845000e+04  78450.000000  78450.000000  \\\n",
       "mean   6.076840e-07  7.473594e-07  1.018405e-06      0.000003      0.000014   \n",
       "min   -9.173519e-06 -8.132207e-06 -3.017080e-06     -0.000033     -0.000021   \n",
       "25%    8.694451e-08  1.027461e-07  3.118676e-07      0.000002      0.000010   \n",
       "50%    3.226519e-07  3.774367e-07  7.283884e-07      0.000003      0.000013   \n",
       "75%    7.965073e-07  9.650466e-07  1.418186e-06      0.000004      0.000016   \n",
       "max    1.597344e-05  1.914169e-05  5.403170e-06      0.000046      0.000050   \n",
       "std    9.464603e-07  1.143633e-06  1.097956e-06      0.000002      0.000007   \n",
       "\n",
       "               50pv          20pv          10pv  \n",
       "count  78450.000000  78450.000000  78450.000000  \n",
       "mean       0.000024      0.000067      0.000171  \n",
       "min       -0.000015      0.000015     -0.000008  \n",
       "25%        0.000020      0.000058      0.000143  \n",
       "50%        0.000023      0.000067      0.000171  \n",
       "75%        0.000027      0.000076      0.000200  \n",
       "max        0.000066      0.000120      0.000360  \n",
       "std        0.000008      0.000015      0.000048  \n",
       "\n",
       "[8 rows x 210 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d6c725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr>0.2:['skt', '700r', '950w', 'wind_speed70_var_8', '900v', 'wind_speed70_avg_8', '800w', '925r', '1000q', '925w', '900r', '900w', '500gh', '600gh', 'fg310', '850w', '925u', 'wind_speed100_max_8', 'wind_speed50_var_8', 'tcw', 'wind_speed50_diff', 'wind_speed_L925_max_8', '400gh', '1000r', 'v10', '925v', 'lsp', 'd2m', '950u', 'wind_speed_L900_avg_8', 'v100', 'wind_speed_L925_avg_8', 'tcwv', '200gh', 'wind_speed10_max_8', '950r', 'wind_speed_L1000_s1', '800q', '800v', '50gh', 'wind_speed_L1000_max_8', 'wind_speed_L1000', 'wind_speed30_diff', 'wind_speed_L950', 'sp', 'wind_speed50_avg_8', '925q', '250gh', 'month', 'lcc', 'wind_speed_L900_max_8', '700gh', '20q', 'wind_speed_L950_avg_8', 'wind_speed30', 'wind_speed_L1000_avg_8', 'wind_speed30_avg_8', '700q', 'wind_speed10_var_8', '850r', '10q', '950v', '900u', 'wind_speed_L950_s1', '950q', 'wind_speed30_max_8', '150gh', 'wind_speed70_max_8', '300t', 'wind_speed70_diff', 'wind_speed50_max_8', 'wind_speed30_var_8', '1000v', 'u10', '1000w', 'tpe', 'wind_speed_L900', 'wind_speed_L900_s1', '800r', 'wind_speed100_var_8', '850q', 'wind_speed100_avg_8', '800u', 'wind_speed10_avg_8', '1000u', '850u', 'mx2t3', '70q', 'u100', 'wind_speed100', '300gh', 'wind_speed_L925_s1', '850v', 'wind_speed_L925', 'wind_speed50', 'wind_speed70', 'p3020', '900q', 'wind_speed_L950_max_8', 'wind_speed10']\n"
     ]
    }
   ],
   "source": [
    "df = speed_direction_features(df) # 合成风向、风速\n",
    "df = get_other_height_speed(df)   # 计算其他高度层的风速\n",
    "\n",
    "df = get_height_speed_diff(df) # 相邻高度风速差\n",
    "df = get_time_features(df) # 加入时间特征\n",
    "ori_feats = ['wind_speed10','wind_speed30','wind_speed50','wind_speed70','wind_speed100','wind_speed_L900','wind_speed_L925','wind_speed_L950','wind_speed_L1000']\n",
    "df = get_window(df,ori_feats)\n",
    "df = get_lag_features(df,ori_feats) # 时滞特征无效\n",
    "# thus=0\n",
    "feats_name = select_features(df,0.2) # 特征筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a62897f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stime</th>\n",
       "      <th>level</th>\n",
       "      <th>time</th>\n",
       "      <th>dtime</th>\n",
       "      <th>time_order</th>\n",
       "      <th>id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>sw_max1</th>\n",
       "      <th>sw_max2</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed_L1000_var_8</th>\n",
       "      <th>wind_speed10_s1</th>\n",
       "      <th>wind_speed30_s1</th>\n",
       "      <th>wind_speed50_s1</th>\n",
       "      <th>wind_speed70_s1</th>\n",
       "      <th>wind_speed100_s1</th>\n",
       "      <th>wind_speed_L900_s1</th>\n",
       "      <th>wind_speed_L925_s1</th>\n",
       "      <th>wind_speed_L950_s1</th>\n",
       "      <th>wind_speed_L1000_s1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70608</td>\n",
       "      <td>70608.0</td>\n",
       "      <td>70608</td>\n",
       "      <td>70608.000000</td>\n",
       "      <td>70608.000000</td>\n",
       "      <td>70608.0</td>\n",
       "      <td>7.060800e+04</td>\n",
       "      <td>7.060800e+04</td>\n",
       "      <td>70608.000000</td>\n",
       "      <td>70608.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70608.000000</td>\n",
       "      <td>67654.000000</td>\n",
       "      <td>67654.000000</td>\n",
       "      <td>67654.000000</td>\n",
       "      <td>67654.000000</td>\n",
       "      <td>67654.000000</td>\n",
       "      <td>67654.000000</td>\n",
       "      <td>67654.000000</td>\n",
       "      <td>67654.000000</td>\n",
       "      <td>67654.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2019-10-02 12:04:46.335826176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-10-04 21:24:15.081577472</td>\n",
       "      <td>57.324652</td>\n",
       "      <td>5.961591</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.020300e+02</td>\n",
       "      <td>2.823000e+01</td>\n",
       "      <td>3.058811</td>\n",
       "      <td>3.293768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190751</td>\n",
       "      <td>1.050654</td>\n",
       "      <td>1.229193</td>\n",
       "      <td>1.322247</td>\n",
       "      <td>1.387356</td>\n",
       "      <td>1.543049</td>\n",
       "      <td>0.873881</td>\n",
       "      <td>0.875159</td>\n",
       "      <td>0.872559</td>\n",
       "      <td>0.873663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-01-01 15:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.020300e+02</td>\n",
       "      <td>2.823000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.004081</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>0.007878</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>0.001728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2018-06-20 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-06-21 14:15:00</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.020300e+02</td>\n",
       "      <td>2.823000e+01</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092175</td>\n",
       "      <td>0.621479</td>\n",
       "      <td>0.727087</td>\n",
       "      <td>0.782130</td>\n",
       "      <td>0.820644</td>\n",
       "      <td>0.805020</td>\n",
       "      <td>0.481682</td>\n",
       "      <td>0.485367</td>\n",
       "      <td>0.482851</td>\n",
       "      <td>0.481798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2019-10-25 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-10-28 00:00:00</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.020300e+02</td>\n",
       "      <td>2.823000e+01</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164302</td>\n",
       "      <td>0.931201</td>\n",
       "      <td>1.089441</td>\n",
       "      <td>1.171916</td>\n",
       "      <td>1.229623</td>\n",
       "      <td>1.367877</td>\n",
       "      <td>0.799097</td>\n",
       "      <td>0.799687</td>\n",
       "      <td>0.797067</td>\n",
       "      <td>0.798635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2021-02-07 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-02-10 06:00:00</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.020300e+02</td>\n",
       "      <td>2.823000e+01</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259649</td>\n",
       "      <td>1.348329</td>\n",
       "      <td>1.577452</td>\n",
       "      <td>1.696871</td>\n",
       "      <td>1.780427</td>\n",
       "      <td>2.085095</td>\n",
       "      <td>1.180896</td>\n",
       "      <td>1.179869</td>\n",
       "      <td>1.176690</td>\n",
       "      <td>1.178622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2021-12-31 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-12-31 21:00:00</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.020300e+02</td>\n",
       "      <td>2.823000e+01</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912768</td>\n",
       "      <td>4.352827</td>\n",
       "      <td>5.092506</td>\n",
       "      <td>5.478028</td>\n",
       "      <td>5.747774</td>\n",
       "      <td>6.728014</td>\n",
       "      <td>3.177345</td>\n",
       "      <td>3.236651</td>\n",
       "      <td>3.229226</td>\n",
       "      <td>3.193826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.947706</td>\n",
       "      <td>5.999920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.421096e-14</td>\n",
       "      <td>1.065822e-14</td>\n",
       "      <td>1.789434</td>\n",
       "      <td>1.793070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129094</td>\n",
       "      <td>0.618779</td>\n",
       "      <td>0.723929</td>\n",
       "      <td>0.778733</td>\n",
       "      <td>0.817079</td>\n",
       "      <td>0.961619</td>\n",
       "      <td>0.499460</td>\n",
       "      <td>0.498596</td>\n",
       "      <td>0.497191</td>\n",
       "      <td>0.497793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               stime    level                           time   \n",
       "count                          70608  70608.0                          70608  \\\n",
       "mean   2019-10-02 12:04:46.335826176      0.0  2019-10-04 21:24:15.081577472   \n",
       "min              2017-01-01 00:00:00      0.0            2017-01-01 15:00:00   \n",
       "25%              2018-06-20 00:00:00      0.0            2018-06-21 14:15:00   \n",
       "50%              2019-10-25 12:00:00      0.0            2019-10-28 00:00:00   \n",
       "75%              2021-02-07 12:00:00      0.0            2021-02-10 06:00:00   \n",
       "max              2021-12-31 12:00:00      0.0            2021-12-31 21:00:00   \n",
       "std                              NaN      0.0                            NaN   \n",
       "\n",
       "              dtime    time_order       id           lon           lat   \n",
       "count  70608.000000  70608.000000  70608.0  7.060800e+04  7.060800e+04  \\\n",
       "mean      57.324652      5.961591      2.0  1.020300e+02  2.823000e+01   \n",
       "min        0.000000      0.000000      2.0  1.020300e+02  2.823000e+01   \n",
       "25%       24.000000      0.000000      2.0  1.020300e+02  2.823000e+01   \n",
       "50%       51.000000      0.000000      2.0  1.020300e+02  2.823000e+01   \n",
       "75%       84.000000     12.000000      2.0  1.020300e+02  2.823000e+01   \n",
       "max      144.000000     12.000000      2.0  1.020300e+02  2.823000e+01   \n",
       "std       39.947706      5.999920      0.0  1.421096e-14  1.065822e-14   \n",
       "\n",
       "            sw_max1       sw_max2  ...  wind_speed_L1000_var_8   \n",
       "count  70608.000000  70608.000000  ...            70608.000000  \\\n",
       "mean       3.058811      3.293768  ...                0.190751   \n",
       "min        0.000000      0.000000  ...                0.002142   \n",
       "25%        1.900000      2.000000  ...                0.092175   \n",
       "50%        3.000000      3.000000  ...                0.164302   \n",
       "75%        4.000000      4.000000  ...                0.259649   \n",
       "max       15.300000     19.900000  ...                0.912768   \n",
       "std        1.789434      1.793070  ...                0.129094   \n",
       "\n",
       "       wind_speed10_s1  wind_speed30_s1  wind_speed50_s1  wind_speed70_s1   \n",
       "count     67654.000000     67654.000000     67654.000000     67654.000000  \\\n",
       "mean          1.050654         1.229193         1.322247         1.387356   \n",
       "min           0.004081         0.004775         0.005136         0.005389   \n",
       "25%           0.621479         0.727087         0.782130         0.820644   \n",
       "50%           0.931201         1.089441         1.171916         1.229623   \n",
       "75%           1.348329         1.577452         1.696871         1.780427   \n",
       "max           4.352827         5.092506         5.478028         5.747774   \n",
       "std           0.618779         0.723929         0.778733         0.817079   \n",
       "\n",
       "       wind_speed100_s1  wind_speed_L900_s1  wind_speed_L925_s1   \n",
       "count      67654.000000        67654.000000        67654.000000  \\\n",
       "mean           1.543049            0.873881            0.875159   \n",
       "min            0.007878            0.003735            0.002310   \n",
       "25%            0.805020            0.481682            0.485367   \n",
       "50%            1.367877            0.799097            0.799687   \n",
       "75%            2.085095            1.180896            1.179869   \n",
       "max            6.728014            3.177345            3.236651   \n",
       "std            0.961619            0.499460            0.498596   \n",
       "\n",
       "       wind_speed_L950_s1  wind_speed_L1000_s1  \n",
       "count        67654.000000         67654.000000  \n",
       "mean             0.872559             0.873663  \n",
       "min              0.004197             0.001728  \n",
       "25%              0.482851             0.481798  \n",
       "50%              0.797067             0.798635  \n",
       "75%              1.176690             1.178622  \n",
       "max              3.229226             3.193826  \n",
       "std              0.497191             0.497793  \n",
       "\n",
       "[8 rows x 273 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"type=='train'\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ef6fa6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.06044293e+00  3.30086337e+00  2.86801472e+02  8.11264930e+01\n",
      " -1.84631317e-02  5.33536530e-01 -5.26189423e-02  1.38367123e+00\n",
      " -2.39929215e-02  7.68964975e+01  9.20660259e-03 -1.97236029e-02\n",
      "  7.68955845e+01 -2.02937999e-02  5.81656130e+03  4.36717982e+03\n",
      "  6.06004930e+00 -2.29121553e-02 -1.20136621e-01  2.79697144e+00\n",
      "  4.84633346e-01  2.12981985e+01  9.29015309e-02  1.55322752e+00\n",
      "  7.52818323e+03  7.68753699e+01 -8.75286196e-02 -5.25310755e-02\n",
      "  3.86738827e-03  2.81672271e+02 -1.13644009e-01  8.74250206e-01\n",
      " -1.42699298e-01  8.75601566e-01  2.11088470e+01  1.23851466e+04\n",
      "  1.92971732e+00  7.68930170e+01  8.72002343e-01  9.20658585e-03\n",
      " -7.74967054e-02  2.06788261e+04  1.54992182e+00  8.74465845e-01\n",
      "  1.78245055e-01  8.73363162e-01  7.80353125e+04  1.31873483e+00\n",
      "  9.20659702e-03  1.08967229e+04  7.25253478e+00  4.01896244e-01\n",
      "  1.55076866e+00  3.10755870e+03  2.99029065e-06  8.72948067e-01\n",
      "  1.22717228e+00  8.74097373e-01  1.22592753e+00  8.12508293e-03\n",
      "  3.05990242e-01  7.68868808e+01  3.15923535e-06 -5.39356953e-02\n",
      " -1.17322881e-01  8.70877567e-01  9.20660860e-03  2.25763575e+00\n",
      "  1.42052286e+04  2.54813238e+00  2.42147416e+02  6.50023316e-02\n",
      "  2.42854722e+00  4.18820505e-01 -5.04536803e-02 -1.45167863e-01\n",
      " -1.59489745e-02  9.25911880e-03  8.74685902e-01  8.72231659e-01\n",
      "  7.68270820e+01  6.89608777e-01  9.20657520e-03  1.53529102e+00\n",
      " -1.15195583e-01  1.04786327e+00 -1.08714870e-01 -1.11400634e-01\n",
      "  2.87545734e+02  3.01423703e-06 -4.50149388e-01  1.54006666e+00\n",
      "  9.62810451e+03  8.73471458e-01 -4.11599393e-02  8.75925587e-01\n",
      "  1.32007381e+00  1.38507614e+00  2.18134346e+04  9.20659252e-03\n",
      "  1.54901911e+00  1.04892722e+00]\n",
      "----------------------------------------\n",
      "Shape of Data (78457, 274)\n",
      "Ageing 24\n",
      "----------------------------------------\n",
      "Network Structure\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden_1 (Dense)                (None, 512)          51712       input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "hidden_2_1 (Dense)              (None, 1024)         525312      hidden_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "hidden_2_2 (Dense)              (None, 512)          524800      hidden_2_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           hidden_2_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 512)          0           dropout_2[0][0]                  \n",
      "                                                                 hidden_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "hidden_3_1 (Dense)              (None, 1024)         525312      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "hidden_3_2 (Dense)              (None, 512)          524800      hidden_3_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           hidden_3_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 512)          0           dropout_3[0][0]                  \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "hidden_4_1 (Dense)              (None, 1024)         525312      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "hidden_4_2 (Dense)              (None, 512)          524800      hidden_4_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 512)          0           hidden_4_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 512)          0           dropout_4[0][0]                  \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "final (Dense)                   (None, 2)            1026        add_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 3,203,074\n",
      "Trainable params: 3,203,074\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Training Data Shape: (55133, 100)\n",
      "Epoch 1/2000\n",
      " 872/1723 [==============>...............] - ETA: 3s - loss: 0.2838"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAgeing\u001b[39m\u001b[38;5;124m'\u001b[39m,ageing)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m df_res \u001b[38;5;241m=\u001b[39m df_query\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mloc[:,:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msw_max2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_X\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[2], line 301\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m    299\u001b[0m lr_callback \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mLearningRateScheduler(lr_scheduler)\n\u001b[0;32m    300\u001b[0m es_callback \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m--> 301\u001b[0m history  \u001b[38;5;241m=\u001b[39m  \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_X\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_y\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_X\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_y\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    305\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cytf\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\.conda\\envs\\cytf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cytf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\.conda\\envs\\cytf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\cytf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\cytf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cytf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_pred={}\n",
    "for ageing in [24,48,72,96,120]:\n",
    "    df,df_query,TRAIN_DATA,VAL_DATA,TEST_DATA = query_cut_dataset(df,ageing,feats_name) # 查询和切分数据\n",
    "    data = load_data(TRAIN_DATA,VAL_DATA,TEST_DATA)\n",
    "    print(\"-\"*40)\n",
    "    print('Shape of Data',df.shape)\n",
    "    print('Ageing',ageing)\n",
    "    print(\"-\"*40)\n",
    "   \n",
    "    model = train_model()\n",
    " \n",
    "    df_res = df_query.query(\"type=='test'\").loc[:,:'sw_max2'].reset_index(drop=True)\n",
    "    y_hat = model.predict(data[\"test_X\"])\n",
    "    # 反归一化\n",
    "    y_hat = data[\"scaler\"].inverse_transform(np.concatenate((y_hat,data[\"test_X\"]),axis=1))[:,:2]\n",
    "    # 神经网络\n",
    "    df_res['nn_sw_max1'] = y_hat[:,0]\n",
    "    df_res['nn_sw_max2'] = y_hat[:,1]\n",
    "    print('df_res.isnull().sum()',df_res.isnull().sum().sum())\n",
    "    # kalman\n",
    "    df_res = kalman_sm_max('sw_max1')\n",
    "    df_res = kalman_sm_max('sw_max2')\n",
    "    # 平均\n",
    "    df_res['ensemble_sw_max1'] = (df_res['nn_sw_max1']+df_res['kalman_sw_max1'])/2\n",
    "    df_res['ensemble_sw_max2'] = (df_res['nn_sw_max2']+df_res['kalman_sw_max2'])/2\n",
    "    test_pred[ageing] = df_res\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb44004",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # 画图分析相关性\n",
    "# df_draw = df.query(\"type=='test'\").drop_duplicates(subset=['time'])\n",
    "# df_draw = df_draw.set_index('time')\n",
    "\n",
    "# df_draw = df_draw.sort_index()\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.rcParams['font.size'] = 15\n",
    "\n",
    "# df_draw[['sw_max1','sw_max2']] = df_draw[['sw_max1','sw_max2']]\n",
    "\n",
    "# df_draw[['wind_speed100','wind_speed_L925','wind_speed10','sw_max1','sw_max2']][:130].dropna().plot(figsize=(20,10))\n",
    "# df_draw = df_draw[['wind_speed100','wind_speed_L925','wind_speed10','sw_max1','sw_max2']]\n",
    "# plt.title('最大浅层风、10米风速、100米风速可视化')\n",
    "# legend_labels = {'wind_speed100': '100米风速', 'wind_speed10': '10米风速', 'sw_max1': '最大浅层风1', 'sw_max2': '最大浅层风2'}\n",
    "# plt.legend(labels=legend_labels.values())\n",
    "# plt.xlabel('时间(间隔3h)')\n",
    "# plt.ylabel('米/秒')\n",
    "# plt.show()\n",
    "\n",
    "# df_corr = pd.DataFrame(df_draw.corr()['sw_max2'])\n",
    "# df_corr = df_corr.sort_values('sw_max2',ascending=False)\n",
    "# # df_corr_2 = df_corr.query('abs(sw_max2)>=0.1')\n",
    "# df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ddb453",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# model.save(\"model/swallow_wind_model_0.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51d00b7",
   "metadata": {},
   "source": [
    "# 推理阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b99f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f920c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_metric(df_res):\n",
    "    for ageing in test_pred.keys():\n",
    "        for name in ['nn_','kalman_','ensemble_']: \n",
    "            for sw_max in ['sw_max1','sw_max2']:\n",
    "                sw_max_mse = mean_squared_error(df_res[name+sw_max], df_res[sw_max])\n",
    "                sw_max_mae = mean_absolute_error(df_res[name+sw_max], df_res[sw_max])\n",
    "                print(str(ageing)+'_'+name+sw_max,sw_max_mse,sw_max_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9246892",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_res = test_pred[24]\n",
    "# for ageing in [48,72,96,120]:\n",
    "#     concated_res = pd.concat([concated_res,test_pred[ageing]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_metric(concated_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39fc860",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0887bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "left='2022-12-01 00:00:00'\n",
    "right='2022-12-30 00:00:00'\n",
    "\n",
    "concated_res.query(\"dtime<=24\").set_index('time').sort_index()[['nn_sw_max1','sw_max1']][left:right].plot()\n",
    "concated_res.query(\"dtime>24 and dtime<=48\").set_index('time').sort_index()[['nn_sw_max1','sw_max1']][left:right].plot()\n",
    "concated_res.query(\"dtime>48 and dtime<=72\").set_index('time').sort_index()[['nn_sw_max1','sw_max1']][left:right].plot()\n",
    "concated_res.query(\"dtime>72 and dtime<=96\").set_index('time').sort_index()[['nn_sw_max1','sw_max1']][left:right].plot()\n",
    "concated_res.query(\"dtime>96 and dtime<=120\").set_index('time').sort_index()[['nn_sw_max1','sw_max1']][left:right].plot()\n",
    "\n",
    "concated_res.query(\"dtime<=24\").set_index('time').sort_index()[['nn_sw_max2','sw_max2']][left:right].plot()\n",
    "concated_res.query(\"dtime>24 and dtime<=48\").set_index('time').sort_index()[['nn_sw_max2','sw_max2']][left:right].plot()\n",
    "concated_res.query(\"dtime>48 and dtime<=72\").set_index('time').sort_index()[['nn_sw_max2','sw_max2']][left:right].plot()\n",
    "concated_res.query(\"dtime>72 and dtime<=96\").set_index('time').sort_index()[['nn_sw_max2','sw_max2']][left:right].plot()\n",
    "concated_res.query(\"dtime>96 and dtime<=120\").set_index('time').sort_index()[['nn_sw_max2','sw_max2']][left:right].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214de01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_res.query(\"dtime<=24\").set_index('time').sort_index()[['nn_sw_max1','sw_max1']]['2022-03-13':'2022-03-17']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ace9d71",
   "metadata": {},
   "source": [
    "## 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7fd433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "_time = datetime.datetime.now().strftime('%Y%m%d%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53bc8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_res.to_csv(f'../../qiancengfeng/result/swallow_wind_{_time}.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a049bbc9",
   "metadata": {},
   "source": [
    "## 数据评测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab5cee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.title(\"Predicted Distribution vs. Actual\")\n",
    "\n",
    "# sns.distplot(df_res_not_null['sw_max_pred_nn'], label=\"y_hat\")\n",
    "# sns.distplot(df_res_not_null['sw_max_true'], label=\"y_true\")\n",
    "# plt.legend()\n",
    "# # plt.savefig(\"pred_dist.jpg\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6490b06c",
   "metadata": {},
   "source": [
    "## 效果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e534a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = df_res.set_index('stime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5edf45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_res[['sw_max_pred_nn','sw_max_true']]['2022-01-16':'2022-01-20'].plot(figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res.to_csv('../qiancengfeng/result/swallow_wind_time_order_12.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b1f81",
   "metadata": {},
   "source": [
    "## 统计每个时刻的指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ece98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def metric_by_attribute(df_res,attribute,true,pred):\n",
    "#     res_dic={}\n",
    "#     for k,v in df_res.groupby(attribute):\n",
    "#     #     rmse = np.sqrt(((v['true']-v['pred'])**2).sum()/len(v))\n",
    "#         rmse = np.sqrt(np.mean((v[true]-v[pred])**2))\n",
    "#         mae = np.mean(np.abs(v[true]-v[pred]))\n",
    "#         res_dic.update({k:[rmse,mae]})\n",
    "\n",
    "#     res = np.array(list(res_dic.values()))\n",
    "\n",
    "#     # 获取横坐标和纵坐标的值\n",
    "#     x_values = list(res_dic.keys())\n",
    "#     res_rmse = res[:,0]\n",
    "#     res_mae = res[:,1]\n",
    "#     # 绘制折线图\n",
    "#     plt.plot(x_values, res_rmse,marker='*',label='rmse')\n",
    "#     # 设置横坐标和纵坐标的标签\n",
    "#     plt.xlabel(attribute)\n",
    "#     plt.ylabel('rmse/mae')\n",
    "#     # 显示图形\n",
    "#     plt.plot(x_values, res_mae,marker='+',label='mae')\n",
    "#     plt.legend()\n",
    "#     # 设置横坐标和纵坐标的标签\n",
    "#     # 显示图形\n",
    "#     plt.show()\n",
    "\n",
    "# metric_by_attribute(df_res.dropna(),'dtime','sw_max_true','sw_max_pred_nn')\n",
    "\n",
    "# ## 统计每个区间的指标\n",
    "\n",
    "# # df_res['true'].hist()\n",
    "# # plt.show()\n",
    "\n",
    "# bins = [0, 2, 4, 6, 12,999]\n",
    "# labels = ['0-2', '2-4', '4-6', '8-12','>12']\n",
    "# # 使用cut函数进行分箱\n",
    "# df_res['sw_max_true_bin'] = pd.cut(df_res['sw_max_true'], bins,labels=labels)\n",
    "\n",
    "# metric_by_attribute(df_res.dropna(),'sw_max_true_bin','sw_max_true','sw_max_pred_nn')\n",
    "\n",
    "# df_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cyenv] *",
   "language": "python",
   "name": "conda-env-.conda-cyenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
